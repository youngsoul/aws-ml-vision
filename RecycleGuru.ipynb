{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# <br>\n",
    "<br>\n",
    "<center><span style=\"font-family:overpass;font-weight:300;font-size:40px;color:#303030;\">Recycle Guru</span></center>\n",
    "<br>\n",
    "<p style=\"font-family:overpass;font-weight:700;font-size:20px;color:#0099FF;text-align:center;margin-top:5px;\">Can I recycle that thing?</p>\n",
    "<br>\n",
    "<img src=\"./notebook_images/ryan-everton-vB6rYZ9rZ6g-unsplash.jpg\" alt=\"Splash\" style=\"width: 20%;\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/pawel-czerwinski-RkIsyD_AVvc-unsplash.jpg\" alt=\"Splash\" style=\"width: 50%;\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Photo by Paweł Czerwiński on Unsplash\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "<br>\n",
    "\n",
    "<span style=\"font-family:overpass;font-size:22px;color:#303030;font-weight:300;\">\n",
    "    Using Machine Learning and Image Classification to help people become better recyclers</span><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Why\n",
    "\n",
    "- 258 million tons of waste to a landfill\n",
    "\n",
    "- 75% of the waste is recyclable and we only recycle around 30%\n",
    "\n",
    "- 80% of items buried in landfill could be recycled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz:  Can you recycle the pizza Box from delivered pizza?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No - technically the bottom should be compost and the unstained top could be recycled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nova Scotia Guidelines on Recycling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./notebook_images/ns_recycle.png\" alt=\"Splash\" style=\"width: 1000%;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Demo\n",
    "\n",
    "Live a demo will be later on\n",
    "\n",
    "<br>\n",
    "<img src=\"data/dataset/coffee_cup/coffee_cup_6ogYO_r.png\" alt=\"Splash\" style=\"width: 50%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Predicted Label: Coffee Cup\n",
      "Predicted Probability: 0.9999706745147705\n",
      "\n",
      "All Predictions: [['Coffee', 9.146626211986586e-07], ['Coffee Cup', 0.9999706745147705], ['Marker', 1.2364926988084335e-05], ['Raspberry Pie', 5.6514263633289374e-06], ['Timmy', 3.5856762679031817e-06], ['Water Bottle', 6.736222985637141e-06]]\n",
      "-------------------\n",
      "Play: Coffee Cup, 0.9999706745147705\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python predict_image_rest_client.py --image-path ./data/data_resize_224_224/coffee_cup/coffee_cup_6ogYO_r.png --api-gateway-url https://n9sg1bdu3c.execute-api.us-east-1.amazonaws.com/test/recycle-guru\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recycle Guru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-family:overpass;font-size:18px;color:#303030;font-weight:300;\">\n",
    "Train an AWS SageMaker model using the <b>image-classifier</b> pre-trained RESNet model to recognize new images labeled as <i>recycleable</i> or <i>not recycleable</i>\n",
    "</span><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/recycle_guru_arch.png\" alt=\"arch\" style=\"width: 90%;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"./notebook_images/coffee_collage.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/coffee_cup_collage.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/markers_collage.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/rpi_collage.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/timmy_collage.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/water_bottle_collage.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resize images to a fixed dimension to match the input_shape of the model, 224 x 224\n",
    "\n",
    "It does appear that SageMaker image-classification will resize images - but I am not clear on how it does it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"./data/dataset/coffee_cup/coffee_cup_6ogYO_r.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "<br>\n",
    "<img src=\"data/data_resize_224_224/coffee_cup/coffee_cup_6ogYO_r.png\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking New Pictures\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/jeff-sheldon-zr8msYQhfRg-unsplash.jpg\" alt=\"Splash\" style=\"width: 40%;\"/>\n",
    "\n",
    "Take some pictures to add as a new dataset\n",
    "\n",
    "\n",
    "Photo by Jeff Sheldon on Unsplash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Taking Picture! \n",
      "Press 's' to take  picture\n",
      "Press 'q' to stop taking pictures\n",
      "Make sure you select the video window before pressing 'q' or 's'\n",
      "Saving picture to: ./data/dataset/coffee_mug/coffee_mug_d3woV_n.png\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python picture_taker.py --data-dir dataset --dataset-name coffee_mug --image-suffix n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/dataset/coffee_cup\n",
      "├── coffee_cup_1W0xm_r.png\n",
      "├── coffee_cup_3LzOB_r.png\n",
      "├── coffee_cup_4Xxbl_r.png\n",
      "├── coffee_cup_4x14D_r.png\n",
      "├── coffee_cup_6dUGO_r.png\n",
      "├── coffee_cup_87xax_r.png\n",
      "├── coffee_cup_9ggOq_r.png\n",
      "├── coffee_cup_BueXl_r.png\n",
      "├── coffee_cup_CCvWo_r.png\n",
      "├── coffee_cup_CF6P5_r.png\n",
      "├── coffee_cup_CkPnb_r.png\n",
      "├── coffee_cup_FY29Q_r.png\n",
      "├── coffee_cup_HC2v8_r.png\n",
      "├── coffee_cup_IdZCa_r.png\n",
      "├── coffee_cup_MJoHO_r.png\n",
      "├── coffee_cup_NpRQk_r.png\n",
      "├── coffee_cup_PxyvF_r.png\n",
      "├── coffee_cup_RAVL3_r.png\n",
      "├── coffee_cup_S0Gdj_r.png\n",
      "├── coffee_cup_SRIHI_r.png\n",
      "├── coffee_cup_SYUB7_r.png\n",
      "├── coffee_cup_SqPFN_r.png\n",
      "├── coffee_cup_T6GO7_r.png\n",
      "├── coffee_cup_TLgho_r.png\n",
      "├── coffee_cup_VIyvy_r.png\n",
      "├── coffee_cup_Xd0Ji_r.png\n",
      "├── coffee_cup_YvX3M_r.png\n",
      "├── coffee_cup_ZDhTG_r.png\n",
      "├── coffee_cup_ZI6or_r.png\n",
      "├── coffee_cup_cznfR_r.png\n",
      "├── coffee_cup_dGDtg_r.png\n",
      "├── coffee_cup_dXPuL_r.png\n",
      "├── coffee_cup_gPBuC_r.png\n",
      "├── coffee_cup_j9Bdu_r.png\n",
      "├── coffee_cup_mqbVu_r.png\n",
      "├── coffee_cup_o7K5h_r.png\n",
      "├── coffee_cup_of4QB_r.png\n",
      "├── coffee_cup_pMNCL_r.png\n",
      "├── coffee_cup_paZGi_r.png\n",
      "├── coffee_cup_ppOGR_r.png\n",
      "├── coffee_cup_pucwm_r.png\n",
      "├── coffee_cup_ttBB3_r.png\n",
      "├── coffee_cup_ujDPI_r.png\n",
      "├── coffee_cup_uq8W9_r.png\n",
      "├── coffee_cup_wrX8z_r.png\n",
      "├── coffee_cup_xVzuT_r.png\n",
      "├── coffee_cup_yFc3a_r.png\n",
      "├── coffee_cup_yHbNv_r.png\n",
      "├── coffee_cup_yPRWt_r.png\n",
      "└── coffee_cup_ywbw0_r.png\n",
      "\n",
      "0 directories, 50 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree ./data/dataset/coffee_cup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize all images for training\n",
    "\n",
    "The CNN has an input shape of 3,224,224 so all of the training pictures needed to be resized to these dimensions.\n",
    "\n",
    "Sometimes that meant adding borders to force the image to be the right size while maintaining the proper aspect ratio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python resize_images.py --from-dir ./data/dataset --to-dir ./data/data_resize --to-size 224 --max-images-per-label 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/data_resize_224_224\n",
      "├── coffee\n",
      "├── coffee_cup\n",
      "├── markers\n",
      "├── raspberry_pi\n",
      "├── timmy\n",
      "└── water_bottle\n",
      "\n",
      "6 directories, 0 files\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "tree ./data/data_resize_224_224 -L 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Manually Upload to S3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model in AWS SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CNN RESNet \n",
    "\n",
    "http://scs.ryerson.ca/~aharley/vis/conv/flat.html\n",
    "\n",
    "Adam Harley. PhD student at Carnegie Mellon University\n",
    "\n",
    "https://www.cs.cmu.edu/~aharley/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "<br>\n",
    "<img src=\"./notebook_images/mitya-ivanov-2HWkORIX3II-unsplash.jpg\" alt=\"Splash\" style=\"width: 60%;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a new picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Taking Picture! \n",
      "Press 's' to take  picture\n",
      "Press 'q' to stop taking pictures\n",
      "Make sure you select the video window before pressing 'q' or 's'\n",
      "Saving picture to: ./data/test_images/test_image/test_image.png\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python picture_taker.py --data-dir test_images --dataset-name test_image --random-part false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<img src=\"./data/test_images/test_image/test_image.png\" alt=\"testimage\" style=\"width: 60%;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python resize_images.py --from-dir ./data/test_images/test_image --to-dir ./data/test_images/test_image_resize --to-size 224 --max-images-per-label 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to classify the picture\n",
    "\n",
    "This will use the API Gateway calling a Lambda Function to execute the SageMaker Model Endpoint passing the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 200\n",
      "Predicted Label: Timmy\n",
      "Predicted Probability: 0.995292067527771\n",
      "\n",
      "All Predictions: [['Coffee', 0.0008162778685800731], ['Coffee Cup', 0.0008889156742952764], ['Marker', 0.00041106590651907027], ['Raspberry Pie', 0.0007351810345426202], ['Timmy', 0.995292067527771], ['Water Bottle', 0.0018564787460491061]]\n",
      "-------------------\n",
      "Play: Timmy, 0.995292067527771\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python predict_image_rest_client.py --image-path ./data/test_images/test_image/test_image.png --api-gateway-url https://n9sg1bdu3c.execute-api.us-east-1.amazonaws.com/test/recycle-guru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python predict_image_rest_client.py --image-path ./data/data_resize_224_224/coffee_cup/coffee_cup_6ogYO_r.png --api-gateway-url https://n9sg1bdu3c.execute-api.us-east-1.amazonaws.com/test/recycle-guru\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges and Lessons Learned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variation and sensitivity to background\n",
    "\n",
    "* Lighting\n",
    "\n",
    "* Number of images.  Need many, many more images\n",
    "\n",
    "* Sagemaker augmentation option\n",
    "\n",
    "* Model Version Control\n",
    "\n",
    "    - We deployed 'old' models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- All Image transforms part of Data Pipeline\n",
    "\n",
    "- Use SageMaker NEO on Raspberry PI\n",
    "\n",
    "- Look for recycle symbol\n",
    "\n",
    "- Crowd source recycle-ability of the item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# At work, I think I can use ___ to ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fraud Detection\n",
    "\n",
    "- Chat Bot, Enhanced Customer Interactions\n",
    "\n",
    "- How to integrate SageMaker into overall solutions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I want to see AWS do ______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Better visualization and data exploration tools\n",
    "\n",
    "- Better developer tools and ability to develop on local machine while integrated with SageMaker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for 5 Million in unsecured loans to move RecycleGuru Forward\n",
    "\n",
    "- bitcoin accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Resources\n",
    "<br>\n",
    "<br>\n",
    "<font size=\"5\">https://github.com/youngsoul/aws-ml-vision</font>\n",
    "<br>\n",
    "<br>\n",
    "<font size=\"5\">www.pyimagesearch.com</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
